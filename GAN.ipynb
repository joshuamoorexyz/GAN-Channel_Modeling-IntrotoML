{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c073aedf-e0d0-4070-8bf2-346796f94d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports & some predefines\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #Use cuda if possible; otherwise eat some threads on the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1fff9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder('Figures/SNR', transform=transform)\n",
    "dataloaded = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e718cf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read one of the data files #TODO: Read all csvs\n",
    "\n",
    "features = ['center_freq', 'dist', 'h_dist', 'v_dist', 'avgPower', 'avgSnr',\n",
    "            'freq_offset', 'avg_pl', 'aod_theta', 'aoa_theta', 'aoa_phi',\n",
    "            'pitch', 'yaw', 'roll', 'vel_x', 'vel_y', 'vel_z', 'speed', 'avg_pl_rolling', 'avg_pl_ewma']\n",
    "\n",
    "df = pd.read_csv(\"dataset/2023-12-15_15_41-results.csv\", usecols = features)\n",
    "\n",
    "\n",
    "#Need to ensure only valid data goes beyond here #TODO\n",
    "\n",
    "data = df[features].values#[:100] Limit values be needed - ask\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data)-seq_length):\n",
    "        x = data[i:(i+seq_length)]\n",
    "        y = data[i+seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "seq_length = 10\n",
    "X, y = create_sequences(data, seq_length)\n",
    "\n",
    "# Convert data to PyTorch tensors - no filter currently, reproduce everything\n",
    "trainX = torch.tensor(X, dtype=torch.float32)\n",
    "trainY = torch.tensor(y, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2d0e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Copy of Aayam's LSMT class - might need to be altered?\n",
    "# class LSTMModel(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "#         super(LSTMModel, self).__init__()\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.layer_dim = layer_dim\n",
    "#         self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "#         self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "#     def forward(self, x, h0=None, c0=None):\n",
    "#         # If hidden and cell states are not provided, initialize them as zeros\n",
    "#         if h0 is None or c0 is None:\n",
    "#             h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "#             c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(x.device)\n",
    "\n",
    "#         # Forward pass through LSTM\n",
    "#         out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "#         out = self.fc(out[:, -1, :])  # Selecting the last output\n",
    "#         return out, hn, cn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78ed9b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize model, loss, and optimizer\n",
    "# model = LSTMModel(input_dim=len(features), hidden_dim=50, layer_dim=1, output_dim=len(features))\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "542241bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Training loop - LSTM\n",
    "# num_epochs = 4000\n",
    "# h0, c0 = None, None  # Initialize hidden and cell states\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     # Forward pass\n",
    "#     outputs, h0, c0 = model(trainX, h0, c0)\n",
    "\n",
    "#     # Compute loss\n",
    "#     loss = criterion(outputs, trainY)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     # Detach hidden and cell states to prevent backpropagation through the entire sequence\n",
    "#     h0 = h0.detach()\n",
    "#     c0 = c0.detach()\n",
    "\n",
    "#     if (epoch+1) % 10 == 0:\n",
    "#         print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ec4f385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO - validate outputs now that it should be for multiple values not just SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24d5c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the Generator\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, inputSize=20, outputSize =(256,256)): #Default input size is 6 (likely needs to be changed); output size is 800x800\n",
    "        super(Generator, self).__init__() #We should be fine using Pytorch base model code\n",
    "\n",
    "        self.outputSize = outputSize #Need to remember the output size for the forward function\n",
    "\n",
    "        self.model = nn.Sequential(nn.Linear(inputSize, 128), #mapping input vector to 128 neurons; \n",
    "                                   nn.LeakyReLU(0.2, inplace=True), #Using inplace=True to save memory + it seems to be standard practice\n",
    "                                   #start hidden layers\n",
    "                                   nn.Linear(128,256), #Hidden Layer 1; Upscaling by factor of 2\n",
    "                                   nn.BatchNorm1d(256), #Normalization\n",
    "                                   nn.LeakyReLU(0.2, inplace=True), \n",
    "                                   nn.Linear(256, 512), #Hidden Layer 2; Upsacling by factor of 2; Last hidden layer for now\n",
    "                                   nn.BatchNorm1d(512), #Normalization\n",
    "                                   nn.LeakyReLU(0.2, inplace=True),\n",
    "                                   nn.Linear(512, outputSize[0] * outputSize[1] * 3), #Output layer; *3 for RGB \n",
    "                                   nn.Tanh() #Normalization for output [-1, 1]\n",
    "                                   )\n",
    "    \n",
    "    #Passes data into first layer & executes sequentially based upon params from self.model()\n",
    "    def forward(self, noise):\n",
    "        genImage =  self.model(noise) #Grab output tensor\n",
    "        return genImage.view(-1, 3, self.outputSize[0], self.outputSize[1]) #Should produce a RGB image using the view function. Args: Batchsize(-1 means figure it out for me), numChannels, height, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a3f12be-c549-4a54-9549-59a1cced6d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, inputSize=(256,256)): #Simple classifier returns [0,1]; 1 real\n",
    "        super(Discriminator, self).__init__() #Use the base Pytorch discriminator\n",
    "\n",
    "        #in channels 3 = RGB data; stride 2 = downscale (1 for no downscale); padding 1 = keep the same size\n",
    "        self.model = nn.Sequential(nn.Conv2d(3, 32, 3, 2, 1), #Convolutional layer 1\n",
    "                                   nn.LeakyReLU(0.2, inplace=True), #Activation function\n",
    "\n",
    "                                   nn.Conv2d(32, 64, 3, 2, 1), #Convolutional layer 1\n",
    "                                   nn.BatchNorm2d(64), #Normalization\n",
    "                                   nn.LeakyReLU(0.2, inplace=True), #Activation function\n",
    "\n",
    "                                   nn.Conv2d(64, 128, 3, 2, 1), #Convolutional layer 2 \n",
    "                                   nn.BatchNorm2d(128), #Normalization\n",
    "                                   nn.LeakyReLU(0.2, inplace=True), #Activation function\n",
    "\n",
    "                                   nn.Conv2d(128, 256, 3, 2, 1), #Convolutional layer 3 \n",
    "                                   nn.BatchNorm2d(256), #Normalization\n",
    "                                   nn.LeakyReLU(0.2, inplace=True), #Activation function\n",
    "                                   \n",
    "                                #    nn.Conv2d(256, 512, 3, 2, 1), #Convolutional layer 4 \n",
    "                                #    nn.BatchNorm2d(512), #Normalization\n",
    "                                #    nn.LeakyReLU(0.2, inplace=True), #Activation function\n",
    "\n",
    "                                #    nn.Conv2d(512, 1, 3, 1, 0), #Output layer \n",
    "\n",
    "                                #    nn.Sigmoid() #Turn the output into [0,1] [batchSize, 1, 13, 13]\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(nn.Linear(256 * (inputSize[0]//16) * (inputSize[1]//16), 1), #Fully connected layer\n",
    "                                nn.Sigmoid() #Turn the output into [0,1] [batchSize, 1]\n",
    "                                )\n",
    "    \n",
    "    #Passes data into first layer & executes sequentially based upon params from self.model() Implicitly called when given input.\n",
    "    def forward(self, input):\n",
    "        # Ensure the input has a channel dimension (batch_size, 1, 800, 800)\n",
    "        if len(input.shape) == 3:  # JIC somehow we got greyscale images\n",
    "            input = input.unsqueeze(1)  # Add channel dimension\n",
    "        \n",
    "        output = self.model(input).view(input.size(0), -1)\n",
    "        return self.fc(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60da67b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be700a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder('Figures/SNR', transform=transform)\n",
    "dataloaded = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "#Hyper params\n",
    "GANepochs = 500\n",
    "GANlr = 0.0002 #Should probably be low\n",
    "\n",
    "#Labels - DO NOT USE 1 or 0, it will be to ridged, smooth it by ~.025 - .2\n",
    "realLabel = 0.9\n",
    "fakeLabel = 0.1\n",
    "\n",
    "#Loss function\n",
    "lossFunc = nn.BCELoss()\n",
    "\n",
    "#Creating the Discriminator\n",
    "discrim = Discriminator().to(DEVICE)\n",
    "dOptimizer = torch.optim.Adam(discrim.parameters(), lr=0.0002, betas=(0.5, 0.999)) #Lower B1 since models will fight eachother\n",
    "\n",
    "#Creating the Generator\n",
    "generator = Generator().to(DEVICE)\n",
    "gOptimizer = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999)) #Lower B1 since models will fight eachother\n",
    "\n",
    "\n",
    "#load data somehow\n",
    "#It would be visualizations of the data no?\n",
    "\n",
    "#static noise\n",
    "#fixedNoise = torch.randn(10, len(features)).to(DEVICE)\n",
    "\n",
    "for epoch in range(GANepochs):\n",
    "    \n",
    "    for i, (realSpectrogram, _) in enumerate(dataloaded):\n",
    "        #realSpectrogram.shape = torch.Size([9, 3, 256, 256])\n",
    "        \n",
    "        #Discriminator Training\n",
    "        realSpectrogram = realSpectrogram.to(DEVICE) #Shove it on the GPU\n",
    "        \n",
    "        real = torch.full((realSpectrogram.size(0), 1), realLabel, device=DEVICE)  # Ensure it has shape [batch_size, 1]\n",
    "        fake = torch.full((realSpectrogram.size(0), 1), fakeLabel, device=DEVICE)  # Ensure it has shape [batch_size, 1]\n",
    "\n",
    "\n",
    "        #Discrim on the real images\n",
    "        dOptimizer.zero_grad() #Zero gradients before training begins\n",
    "        output = discrim(realSpectrogram)\n",
    "        dLossOnReal = lossFunc(output, real)\n",
    "\n",
    "        #Discrim on fake data\n",
    "        noise = torch.randn(realSpectrogram.size(0), len(features)).to(DEVICE)\n",
    "        fakeSpectrogram = generator(noise)\n",
    "        output = discrim(fakeSpectrogram.detach()) #Detach - not training the generator yet\n",
    "        dLossOnFake = lossFunc(output, fake)\n",
    "\n",
    "        #Combined Loss\n",
    "        dLossTotal = dLossOnReal + dLossOnFake\n",
    "        dLossTotal.backward()\n",
    "        dOptimizer.step()\n",
    "        \n",
    "        #Train the generator\n",
    "        gOptimizer.zero_grad() #Zero gradients before training begins\n",
    "        output = discrim(fakeSpectrogram) #not calling deteach - training the generator\n",
    "        output = output.view(-1, 1) #Flatten the output to match label\n",
    "        gLoss = lossFunc(output, real) #BLOODY PROGRESS\n",
    "        gLoss.backward()\n",
    "        gOptimizer.step()\n",
    "\n",
    "        #output so we know something happened\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{GANepochs}], D Loss: {dLossTotal.item():.4f}, G Loss: {gLoss.item():.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9374d353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
