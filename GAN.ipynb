{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b9e8e39d-2264-4f94-a3e7-c36b074880ae",
      "metadata": {
        "id": "b9e8e39d-2264-4f94-a3e7-c36b074880ae"
      },
      "source": [
        "\n",
        "\n",
        "# CSE 4693/6693 Intro to Machine Learning\n",
        "\n",
        "## Project: LSTM-GAN Based Wireless Channel Modeling\n",
        "\n",
        "<div style=\"float: left; margin-right: 20px;\">\n",
        "\n",
        "| Name | NetID |\n",
        "|:-----|:------|\n",
        "| Joshua Moore | jjm702 |\n",
        "| Tirian Judy | tkj105 |\n",
        "| Claire Johnson | kj1289 |\n",
        "| Aayam Raj Shakya | as5160 |\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c073aedf-e0d0-4070-8bf2-346796f94d69",
      "metadata": {
        "id": "c073aedf-e0d0-4070-8bf2-346796f94d69"
      },
      "outputs": [],
      "source": [
        "# Imports & some predefines\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Use cuda if possible; otherwise eat some threads on the CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "78ed9b38",
      "metadata": {
        "id": "78ed9b38"
      },
      "outputs": [],
      "source": [
        "# Data parsing\n",
        "\n",
        "'''\n",
        "This is the data we want to load\n",
        "Distance (dist): Between the UAV and the receiver.\n",
        "Altitude (alt): UAV height above ground.\n",
        "Frequency (freq): Operating frequencies measured.\n",
        "UAV Speed (vel_x, vel_y): UAV mobility, affecting Doppler shifts.\n",
        "Environment Type: Use categorical encoding for rural/open field or terrain information.\n",
        "LOS/NLOS Classification: A binary or probabilistic input indicating line-of-sight status.\n",
        "'''\n",
        "\n",
        "CENTER_FREQ = 3564\n",
        "file_path = 'dataset/'\n",
        "\n",
        "# Read all CSV files\n",
        "arrays = [pd.read_csv(file).rename(columns=lambda x: x.strip()) for file in glob.glob(file_path + \"*.csv\")]\n",
        "\n",
        "# Filter the columns in each dataframe, and include only the ones that exist in the dataframe\n",
        "filtered_arrays = []\n",
        "\n",
        "'''\n",
        "path loss ewma is ...\n",
        "aod_theta, aod_phi: Angles of Departure in the vertical (elevation) and horizontal (azimuth) planes\n",
        "aoa_theta, aoa_phi: Angles of Arrival in the vertical (elevation) and horizontal (azimuth) planes\n",
        "These angles are critical for beamforming, MIMO systems, and propagation modeling, as they help in\n",
        "determining the direction of signal transmission (AOD) and reception (AOA), improving channel\n",
        "estimation and system optimization.\n",
        "\n",
        "AOD (Angle of Departure) and AOA (Angle of Arrival) are calculated based on the relative positions\n",
        "of the transmitter (UAV) and receiver (target) in both horizontal (azimuth) and vertical (elevation) planes.\n",
        "\n",
        "Horizontal (Azimuth) Angle (phi):\n",
        "phi = atan2((y_target - y_uav), (x_target - x_uav))\n",
        "\n",
        "Vertical (Elevation) Angle (theta):\n",
        "theta = atan2((z_target - z_uav), sqrt((x_target - x_uav)^2 + (y_target - y_uav)^2))\n",
        "\n",
        "These angles are essential for beamforming, signal propagation modeling, and estimating the channel conditions.\n",
        "\n",
        "for original peaks and peaks we need to process data and only include when it has 4 items in the array\n",
        "'peaks' represents the indices where the processed signal exhibits local maxima, potentially indicating key events such as\n",
        "moments of high signal strength or important changes in the UAV's movement (e.g., rapid shifts in altitude or speed).\n",
        "'orig_peaks' shows the indices of maxima in the raw, unprocessed data, which could reflect more noise or less clarity.\n",
        "These peak points are essential for analyzing signal behavior, especially in the context of parameters like distance ('dist'),\n",
        "altitude ('alt'), frequency offset should change, and UAV velocity ('vel_x', 'vel_y') this tells us if the UAV is moving, as they might correlate with specific moments\n",
        "when the signal is strongest or when significant changes in the UAVâ€™s position or mobility occur.\n",
        "'''\n",
        "\n",
        "columns_to_keep = ['dist', 'avgSnr', 'freq_offset','avgPower', 'avg_pl','avg_pl_ewma', 'aod_theta','aoa_theta', 'peaks', 'orig_peaks','speed', 'stage', 'vel_x', 'vel_y','vel_z']\n",
        "\n",
        "# Process the data\n",
        "for df in arrays:\n",
        "    # Keep only the relevant columns that exist in the dataframe\n",
        "    existing_columns = [col for col in columns_to_keep if col in df.columns.str.strip()]\n",
        "    filtered_df = df[existing_columns]\n",
        "\n",
        "    if 'stage' in filtered_df.columns:\n",
        "        filtered_df = filtered_df[filtered_df['stage'] == 'Flight']\n",
        "\n",
        "    # if 'peaks' in filtered_df.columns:\n",
        "    #     filtered_df['peaks'] = filtered_df['peaks'].apply(lambda x: [i for i in x.split() if i.strip()][1:-1] if isinstance(x, str) else x)\n",
        "    #     print(filtered_df['peaks'])\n",
        "\n",
        "    filtered_arrays.append(filtered_df)\n",
        "\n",
        "# Print the first 5 rows of the first dataframe (for verification)\n",
        "# print(filtered_arrays[0].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "24d5c30c",
      "metadata": {
        "id": "24d5c30c"
      },
      "outputs": [],
      "source": [
        "# Build the Generator\n",
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, inputSize=6, outputSize =(48,48)): # LSTM model should produce a vector of 6 terms; Output an array of 48H * 48W\n",
        "        super(Generator, self).__init__() # We should be fine using Pytorch base model code\n",
        "\n",
        "        self.outputSize = outputSize # Need to remember the output size for the forward function\n",
        "\n",
        "        self.model = nn.Sequential(nn.Linear(inputSize, 128), # Mapping input vector to 128 neurons;\n",
        "                                   nn.LeakyReLU(0.2, inplace=True), # Using inplace=True to save memory + it seems to be standard practice\n",
        "                                   # Start hidden layers\n",
        "                                   nn.Linear(128,256), # Hidden Layer 1; Upscaling by factor of 2\n",
        "                                   nn.BatchNorm1d(256), # Normalization\n",
        "                                   nn.LeakyReLU(0.2, inplace=True),\n",
        "                                   nn.Linear(256, 512), # Hidden Layer 2; Upsacling by factor of 2; Last hidden layer for now\n",
        "                                   nn.BatchNorm1d(512), # Normalization\n",
        "                                   nn.LeakyReLU(0.2, inplace=True),\n",
        "                                   nn.Linear(512, outputSize[0] * outputSize[1]), # Output layer\n",
        "                                   nn.Tanh() # Normalization for output (-1, 1)\n",
        "                                   )\n",
        "\n",
        "    # Passes data into first layer & executes sequentially based upon params from self.model()\n",
        "    def forward(self, noise):\n",
        "        genImage =  self.model(noise) # Grab output tensor\n",
        "        return genImage.view(-1, 1, self.outputSize[0], self.outputSize[1]) # Should produce a grey scale image using the view function. Args: Batchsize(-1 means figure it out for me), numChannels, height, width"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9a3f12be-c549-4a54-9549-59a1cced6d0b",
      "metadata": {
        "id": "9a3f12be-c549-4a54-9549-59a1cced6d0b"
      },
      "outputs": [],
      "source": [
        "# Build the Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, inputSize=(48,48)): # Simple classifier returns [0,1]; 1 real\n",
        "        super(Discriminator, self).__init__() # Use the base Pytorch discriminator\n",
        "\n",
        "        self.inputSize = inputSize # Need to remember the input size for the forward function\n",
        "\n",
        "        self.model = nn.Sequential(nn.Linear(inputSize[0] * inputSize[1], 512), # Mapping input vector to 512 neurons\n",
        "                                   nn.LeakyReLU(0.2, inplace=True),\n",
        "                                   nn.Linear(512, 256), # Hidden Layer 1; Downscaling by factor of 2\n",
        "                                   nn.LeakyReLU(0.2, inplace=True),\n",
        "                                   nn.Linear(256, 1), # Output layer - Map 256 neurons into the probability of being real\n",
        "                                   nn.Sigmoid() # Turn the output into [0,1]\n",
        "                                   )\n",
        "\n",
        "    def forward(self, input):\n",
        "        flatInput = input.view(input.size(0), -1) # Flatten the input to 1D\n",
        "        return self.model(flatInput)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4be700a5",
      "metadata": {
        "id": "4be700a5"
      },
      "outputs": [],
      "source": [
        "# Initializing GAN Components\n",
        "\n",
        "# Loss function\n",
        "losFunc = nn.BCELoss()\n",
        "\n",
        "# Creating the Discriminator\n",
        "discrim = Discriminator().to(DEVICE)\n",
        "dOptimizer = optim.Adam(discrim.parameters(), lr=0.0002, betas=(0.5, 0.999)) # Lower B1 since models will fight each other\n",
        "\n",
        "# Creating the Generator\n",
        "generator = Generator().to(DEVICE)\n",
        "gOptimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999)) # Lower B1 since models will fight each other"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}