{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c073aedf-e0d0-4070-8bf2-346796f94d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from PIL import Image\n",
    "\n",
    "#Autoencoder\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, latent_dim, output_channels=1, img_size=28):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),  # Compress input to 128 units\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, latent_dim)  # Latent space\n",
    "        )\n",
    "        \n",
    "        # Decoder: Fully connected layers to reshape into image\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),  # Latent to 128 units\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_channels * img_size * img_size),  # Output flattened image size\n",
    "            nn.Sigmoid()  # Output in range [0, 1]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        image = self.decoder(x)\n",
    "        image = image.view(-1, 1, 28, 28)\n",
    "        return image\n",
    "\n",
    "#Globals\n",
    "source_dir = \"./../dataset/reduced_only_full/\"\n",
    "output_dir = \"./../dataset/visuals/\"\n",
    "chunk_size = 100\n",
    "components = 19\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "auto_encoder = Autoencoder(input_size=components, latent_dim=64, output_channels=1, img_size=28).to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(auto_encoder.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fff9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(source_dir):\n",
    "    print(f\"Found: {file}\")\n",
    "    if file.endswith(\".csv\"):\n",
    "        #Load the dataset\n",
    "        file_path = os.path.join(source_dir, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        #Base target for writing for results from this file\n",
    "        folder_base = file.replace(\".csv\", \"\")\n",
    "        # base_hm_path = f\"{output_dir}{folder_base}_HM\"\n",
    "        # base_sp_matrix_path = f\"{output_dir}{folder_base}_SP_Matrix\"\n",
    "        # base_sp_path = f\"{output_dir}{folder_base}_SP\"\n",
    "        base_ae_path = f\"{output_dir}{folder_base}_AE\"\n",
    "\n",
    "        #Make the directories\n",
    "        # os.makedirs(base_hm_path, exist_ok=True)\n",
    "        # os.makedirs(base_sp_matrix_path, exist_ok=True)\n",
    "        # os.makedirs(base_sp_path, exist_ok=True)\n",
    "        os.makedirs(base_ae_path, exist_ok=True)\n",
    "\n",
    "        #For each chunk\n",
    "        for i in range(len(df) // chunk_size):\n",
    "            start_idx = i * chunk_size\n",
    "            end_idx = start_idx + chunk_size\n",
    "            df_chunk = df.iloc[start_idx:end_idx]\n",
    "\n",
    "\n",
    "            #Autoencoder approach\n",
    "            #Convert to tensor\n",
    "            data = torch.tensor(df_chunk.values, dtype=torch.float32).to(DEVICE)\n",
    "            output_image = auto_encoder(data)\n",
    "            output_image = output_image.cpu().detach().numpy() #NEED to detach before conversion\n",
    "\n",
    "            output_image = output_image.squeeze(1)\n",
    "\n",
    "            if output_image.max() <= 1:\n",
    "                output_image = (output_image * 255).astype(np.uint8)\n",
    "\n",
    "            grid_image = np.concatenate([np.concatenate(output_image[i*10:(i+1)*10], axis=1) for i in range(10)], axis=0)\n",
    "\n",
    "            grid_image_pil = Image.fromarray(grid_image.astype(np.uint8))\n",
    "            grid_image_pil.save(f\"{base_ae_path}/AE_PIL_{i+1}.png\")\n",
    "\n",
    "            # #Heatmap image - No way to get back to data points\n",
    "            # plt.figure(figsize=(10, 8))\n",
    "            # sns.heatmap(df_chunk.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "            # plt.title(f\"Correlation Heatmap (Chunk {i+1})\")\n",
    "            # hm_path = os.path.join(base_hm_path, f\"Heatmap_{i+1}.png\")\n",
    "            # plt.savefig(hm_path)\n",
    "            # plt.close()\n",
    "\n",
    "            # #Pairplot - Takes a long time, \n",
    "            # plt.figure(figsize=(15, 15))\n",
    "            # pair_plot = sns.pairplot(df_chunk, diag_kind='hist')\n",
    "            # plt.title(f\"Scatter Matrix (Chunk {i+1})\")\n",
    "            # sp_matrix_path = os.path.join(base_sp_matrix_path, f\"SP_Matrix_{i+1}.png\")\n",
    "            # pair_plot.savefig(sp_matrix_path)\n",
    "            # plt.close()\n",
    "\n",
    "            # #3D plot - 8 Features\n",
    "            # dist = df_chunk['dist'].values\n",
    "            # h_dist = df_chunk['h_dist'].values\n",
    "            # v_dist = df_chunk['v_dist'].values\n",
    "            # avgPower = df_chunk['avgPower'].values \n",
    "            # avgSnr = df_chunk['avgSnr'].values\n",
    "            # avg_pl = df_chunk['avg_pl'].values\n",
    "\n",
    "            # #3D plotting\n",
    "            # fig = plt.figure(figsize=(10, 8))\n",
    "            # ax = fig.add_subplot(111, projection='3d')\n",
    "            # sc = ax.scatter(dist, h_dist, v_dist, c=avgPower, cmap='viridis', s=avg_pl, alpha=0.7)\n",
    "            # fig.colorbar(sc, label='Average Power')\n",
    "            # sp_path = os.path.join(base_sp_path, f\"SP_{i+1}.png\")\n",
    "            # plt.savefig(sp_path)\n",
    "            # plt.close()\n",
    "            \n",
    "\n",
    "            print(f\"Chunk {i+1} visualization saved for {file}!\")\n",
    "\n",
    "print(\"All visualizations saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d88f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_image_path = \"../dataset/visuals/2023-12-15_15_41-results_AE/AE_4.png\"\n",
    "image_as_array = plt.imread(ae_image_path) #its a PNG its already in range\n",
    "image_as_array.flatten()\n",
    "tensor = torch.tensor(image_as_array, dtype=torch.float32).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "        reconstructed_data = auto_encoder.decoder[0:2](tensor)  # Get only the decoder layers\n",
    "        reconstructed_data = reconstructed_data.cpu().numpy().flatten()\n",
    "\n",
    "reconstructed_df = pd.DataFrame(reconstructed_data.reshape(1, -1))\n",
    "print(reconstructed_df)\n",
    "# latent_vetor = auto_encoder.encoder(tensor)\n",
    "# latent_vetor = latent_vetor.cpu().detach().numpy()\n",
    "# print(latent_vetor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
