{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c073aedf-e0d0-4070-8bf2-346796f94d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.48353836 0.45350114 0.51018274 ... 0.4955537  0.4879785  0.49731788]\n",
      " [0.48353907 0.45350015 0.5101837  ... 0.4955537  0.4879778  0.49731725]\n",
      " [0.48353076 0.4535226  0.5101875  ... 0.4955384  0.4879921  0.49732003]\n",
      " ...\n",
      " [0.4835331  0.45350906 0.51017696 ... 0.4955568  0.48797157 0.49733052]\n",
      " [0.48352614 0.45351452 0.510182   ... 0.49555522 0.48798802 0.4973084 ]\n",
      " [0.4835704  0.45347157 0.510227   ... 0.49550757 0.48795727 0.4973656 ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from math import ceil\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from PIL import Image\n",
    "\n",
    "#Autoencoder for producing images\n",
    "#Assuming input is 19; allow for change of hidden size and lowered default latent_dim\n",
    "class CSVEncoder(nn.Module):\n",
    "    def __init__(self, input_size=19, hidden_size=128, latent_dim=8, output_size=None):\n",
    "        super(CSVEncoder, self).__init__()\n",
    "        self.output_size = output_size if output_size is not None else input_size\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, latent_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, self.output_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "#Autoencoder for decoding the images\n",
    "#Only one channel needed - greyscale\n",
    "class IMGAutoencoder(nn.Module):\n",
    "    def __init__(self, output_channels=1):\n",
    "        super(IMGAutoencoder, self).__init__()\n",
    "\n",
    "        #Encoder: Compress image\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1), #[batch, 16, 28, 28]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),             #[batch, 16, 14, 14]\n",
    "            nn.Conv2d(16, 8, 3, padding=1), #[batch, 8, 14, 14]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)              #[batch, 8, 7, 7]\n",
    "        )\n",
    "        \n",
    "        #Decoder: Decompress image\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 16, 3, stride=2, padding=1, output_padding=1),                #[batch, 16, 14, 14]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, output_channels, 3, stride=2, padding=1, output_padding=1),  #[batch, 1, 28, 28]\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "#Globals\n",
    "source_dir = \"./../dataset/reduced_only_full/\"\n",
    "output_dir = \"./../dataset/visuals/\"\n",
    "chunk_size = 100\n",
    "components = 19\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "csv_encoder = CSVEncoder(input_size=19, hidden_size=128, latent_dim=8).to(DEVICE)\n",
    "img_autoencoder = IMGAutoencoder(output_channels=1).to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(csv_encoder.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fff9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(source_dir):\n",
    "    print(f\"Found: {file}\")\n",
    "    if file.endswith(\".csv\"):\n",
    "        #Load the dataset\n",
    "        file_path = os.path.join(source_dir, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        #Base target for writing for results from this file\n",
    "        folder_base = file.replace(\".csv\", \"\")\n",
    "        # base_hm_path = f\"{output_dir}{folder_base}_HM\"\n",
    "        # base_sp_matrix_path = f\"{output_dir}{folder_base}_SP_Matrix\"\n",
    "        # base_sp_path = f\"{output_dir}{folder_base}_SP\"\n",
    "        base_ae_path = f\"{output_dir}{folder_base}_AE\"\n",
    "\n",
    "        #Make the directories\n",
    "        # os.makedirs(base_hm_path, exist_ok=True)\n",
    "        # os.makedirs(base_sp_matrix_path, exist_ok=True)\n",
    "        # os.makedirs(base_sp_path, exist_ok=True)\n",
    "        os.makedirs(base_ae_path, exist_ok=True)\n",
    "\n",
    "        #For each chunk\n",
    "        for i in range(ceil(len(df) / chunk_size)):\n",
    "            start_idx = i * chunk_size\n",
    "            end_idx = min(start_idx + chunk_size, len(df))\n",
    "            df_chunk = df.iloc[start_idx:end_idx]\n",
    "\n",
    "\n",
    "            #Autoencoder approach\n",
    "            #Convert to tensor\n",
    "            data = torch.tensor(df_chunk.values, dtype=torch.float32).to(DEVICE)\n",
    "            output_image = csv_encoder(data)\n",
    "            output_image = output_image.cpu().detach().numpy() #NEED to detach before conversion\n",
    "\n",
    "            output_image = output_image.reshape(10, 10, 28, 28)  # Reshape to create 10x10 grid\n",
    "\n",
    "            if output_image.max() <= 1:\n",
    "                output_image = (output_image * 255).astype(np.uint8)\n",
    "\n",
    "            grid_image = np.concatenate([np.concatenate(output_image[i], axis=1) for i in range(10)], axis=0)\n",
    "\n",
    "            grid_image_pil = Image.fromarray(grid_image.astype(np.uint8))\n",
    "            grid_image_pil.save(f\"{base_ae_path}/AE_PIL_{i+1}.png\")\n",
    "\n",
    "            # #Heatmap image - No way to get back to data points\n",
    "            # plt.figure(figsize=(10, 8))\n",
    "            # sns.heatmap(df_chunk.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "            # plt.title(f\"Correlation Heatmap (Chunk {i+1})\")\n",
    "            # hm_path = os.path.join(base_hm_path, f\"Heatmap_{i+1}.png\")\n",
    "            # plt.savefig(hm_path)\n",
    "            # plt.close()\n",
    "\n",
    "            # #Pairplot - Takes a long time, \n",
    "            # plt.figure(figsize=(15, 15))\n",
    "            # pair_plot = sns.pairplot(df_chunk, diag_kind='hist')\n",
    "            # plt.title(f\"Scatter Matrix (Chunk {i+1})\")\n",
    "            # sp_matrix_path = os.path.join(base_sp_matrix_path, f\"SP_Matrix_{i+1}.png\")\n",
    "            # pair_plot.savefig(sp_matrix_path)\n",
    "            # plt.close()\n",
    "\n",
    "            # #3D plot - 8 Features\n",
    "            # dist = df_chunk['dist'].values\n",
    "            # h_dist = df_chunk['h_dist'].values\n",
    "            # v_dist = df_chunk['v_dist'].values\n",
    "            # avgPower = df_chunk['avgPower'].values \n",
    "            # avgSnr = df_chunk['avgSnr'].values\n",
    "            # avg_pl = df_chunk['avg_pl'].values\n",
    "\n",
    "            # #3D plotting\n",
    "            # fig = plt.figure(figsize=(10, 8))\n",
    "            # ax = fig.add_subplot(111, projection='3d')\n",
    "            # sc = ax.scatter(dist, h_dist, v_dist, c=avgPower, cmap='viridis', s=avg_pl, alpha=0.7)\n",
    "            # fig.colorbar(sc, label='Average Power')\n",
    "            # sp_path = os.path.join(base_sp_path, f\"SP_{i+1}.png\")\n",
    "            # plt.savefig(sp_path)\n",
    "            # plt.close()\n",
    "            \n",
    "\n",
    "            print(f\"Chunk {i+1} visualization saved for {file}!\")\n",
    "\n",
    "print(\"All visualizations saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d88f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "ae_image_path = \"../dataset/visuals/2023-12-15_15_41-results_AE/AE_PIL_1.png\"\n",
    "\n",
    "stiched_image = Image.open(ae_image_path)\n",
    "\n",
    "#Convert to numpy array 280x280\n",
    "stiched_image = np.array(stiched_image)\n",
    "\n",
    "images = []\n",
    "\n",
    "#Split into 100 28x28 images\n",
    "for w in range(10):\n",
    "    for h in range(10):\n",
    "        image = stiched_image[w*28:(w+1)*28, h*28:(h+1)*28]\n",
    "        images.append(image)\n",
    "\n",
    "images_tensor = torch.tensor(images).float().unsqueeze(1).to(DEVICE)\n",
    "img_autoencoder.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    #Decode the images\n",
    "    decoded_images = img_autoencoder(images_tensor)\n",
    "    \n",
    "    #Flatten the images to 28*28 dimensions\n",
    "    flattened = decoded_images.view(decoded_images.size(0), -1)  # Shape: [100, 784]\n",
    "    \n",
    "    #Create a new reverse encoder by flipping input & output size\n",
    "    reverse_encoder = CSVEncoder(input_size=28*28, hidden_size=128, output_size=19).to(DEVICE)\n",
    "    \n",
    "    #Convert back to features\n",
    "    final_features = reverse_encoder(flattened)\n",
    "\n",
    "    final_features = final_features.cpu().detach().numpy()\n",
    "    print(final_features) #SOMETHING IS WRONG "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
